{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chuẩn hoá các hàm thông dụng.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ngonam2403/VEF-Final-Project_202007/blob/master/Chu%E1%BA%A9n_ho%C3%A1_c%C3%A1c_h%C3%A0m_th%C3%B4ng_d%E1%BB%A5ng.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9_g8VWyaptW",
        "colab_type": "text"
      },
      "source": [
        "#Mục đích: để tra cứu & tái sử dụng\n",
        "---\n",
        "Format chung: \n",
        "1. mục đích hàm\n",
        "2. input (dataframe, list) --> output (number, dataframe, chart)\n",
        "3. cần library nào để chạy? pandas, numpy, scikitlearn, seaborn\n",
        "\n",
        "---\n",
        "Cách đặt tên phần tử (Naming Convention): mục đích của việc này là để người khác dễ đọc và mường tượng được code của mình.\n",
        "thứ tự ưu tiên: mục đích -> loại -> tên riêng để định danh.\n",
        "- hàm: động từ, ví dụ def create_table() hoặc def plot_chart().\n",
        "- biến: danh từ\n",
        "  - dataframe: df_, ví dụ: thay vì viết data = pd.read_csv() thì viết df_abc = pd.read_csv(). nếu dataframe là một param trong hàm thì nên viết def create_table(param_df_xyz).\n",
        "  - một con số: num_\n",
        "  - text: str_\n",
        "    \n",
        "- lúc dùng thì ghi rõ param1 = , param2 =, param3 = \n",
        "- khi hàm có quá nhiều param thì chuyển sang dùng class,\n",
        "- class: CamelCase\n",
        "\n",
        "- tham khảo: https://www.analyticsvidhya.com/blog/2020/07/python-style-guide/; https://towardsdatascience.com/data-scientists-your-variable-names-are-awful-heres-how-to-fix-them-89053d2855be\n",
        "---\n",
        "flow chạy, pipeline.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_248h71Tfw1x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Don't do this\n",
        "temp = get_house_price_in_usd(house_sqft, house_room_count)\n",
        "final_value = temp * usd_to_aud_conversion_rate\n",
        "# Do this instead\n",
        "house_price_in_usd = get_house_price_in_usd(house_sqft, \n",
        "                                            house_room_count)\n",
        "house_price_in_aud = house_price_in_usd * usd_to_aud_conversion_rate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9nXaaW2g3dX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for row_index in range(row_count):\n",
        "    for column_index in range(column_count):\n",
        "        ...."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TPuhfdohFN5",
        "colab_type": "text"
      },
      "source": [
        "The benefits of adopting standards are that they let you make a single global decision instead of many local ones."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7otUwK3khF9u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JX9dxYEtxuOK",
        "colab_type": "text"
      },
      "source": [
        "#0.Basic Statistics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0_lCRzDxzy8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# app_train = pd.read_csv('../input/application_train.csv')\n",
        "\n",
        "print('Training data shape: ', app_train.shape) #df.shape\n",
        "\n",
        "app_train.info() #1 #better than df.describe()\n",
        "app_train.dtypes #2\n",
        "app_train.columns\n",
        "app_train.describe() #3\n",
        "\n",
        "\n",
        "#column type\n",
        "# Number of each type of column\n",
        "app_train.dtypes.value_counts()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVkFWK4g0b2s",
        "colab_type": "text"
      },
      "source": [
        "# 1.Các hàm biến đổi-clean-transform dữ liệu\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XBcDLSLsHOK",
        "colab_type": "text"
      },
      "source": [
        "##1.1. Xử lý missing data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLxReWS7VWe5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "FUNCTION: CHECK MISSING DATA\n",
        "input: a dataframe MxN --> output: a dataframe Nx2\n",
        "need: pandas\n",
        "\"\"\"\n",
        "def create_table_missing_values(df):\n",
        "    mis_val = df.isnull().sum() #total missing values #input: df MxN -> output: df Nx2\n",
        "    mis_val_percent = 100 * df.isnull().sum() / len(df) #percentage of missing values #input: df MxN -> output: df Nx2\n",
        "    mis_val_table = pd.concat( #join df mis_val and df mis_val_percent\n",
        "        [mis_val, mis_val_percent], \n",
        "        axis=1\n",
        "        ) \n",
        "    mis_val_table_ren_columns = mis_val_table.rename( #rename the columns\n",
        "        columns = {\n",
        "            0 : 'Missing values', \n",
        "            1 : '% of Total Values'\n",
        "            }\n",
        "        )\n",
        "    mis_val_table_ren_columns = mis_val_table_ren_columns[ #sort the table by percentage of missing descending\n",
        "        mis_val_table_ren_columns.iloc[:,1] != 0].sort_values('% of Total Values', ascending=False).round(1) #exclude those has 0% missing.\n",
        "    \n",
        "    print(\"Your selected dataframe has \")    \n",
        "    return mis_val_table_ren_columns\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "FUNCTION: REMOVE COLUMNS THAT HAS MISSING DATA ABOVE A THRESOLD, default 90%.\n",
        "input: a dataframe MxN --> output: a dataframe MxK\n",
        "need: pandas\n",
        "\"\"\"\n",
        "def remove_column_missing(df, threshold = 90):\n",
        "  tb_missing_column = create_table_missing_values(df)\n",
        "  list_missing_column = list(tb_missing_column.index[tb_missing_column['% of Total Values'] > threshold ])\n",
        "  df_removed = df.drop(columns = list_missing_column)\n",
        "  return df_removed\n",
        "  print('There are {} columns removed.'.format(len(list_missing_column)))\n",
        "\n",
        "# missing_train = create_table_missing_values(app_train)\n",
        "# missing_train.head(10)\n",
        "\n",
        "# list_train_variables_missing = list(missing_train.index[missing_train['% of Total Values'] > 90]) #pd.index #list(pd.index)\n",
        "# len(missing_train_vars) #0\n",
        "\n",
        "# list_test_variables_missing = list(missing_test.index[missing_test['% of Total Values'] > 90])\n",
        "# len(missing_test_vars) #0\n",
        "\n",
        "# missing_columns = list(set(missing_test_vars + missing_train_vars))\n",
        "# print('There are %d columns with more than 90%% missing in either the training or testing data.' % len(missing_columns))\n",
        "\n",
        "# # Drop the missing columns\n",
        "# train = train.drop(columns = missing_columns)\n",
        "# test = test.drop(columns = missing_columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQVGi8XV9EWy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"FUNCTION: impute numerical\"\"\"\n",
        "from sklearn.preprocessing import Imputer\n",
        "application[numerical_list] = Imputer(strategy='median').fit_transform(\n",
        "    application[numerical_list])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7GrD4Cbsmes",
        "colab_type": "text"
      },
      "source": [
        "##1.2. Xử lý biến dạng categorical"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAps9q1RslTK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# One-hot encoding for categorical columns with get_dummies\n",
        "def encode_one_hot(df, nan_as_category = True):\n",
        "    original_columns = list(df.columns)\n",
        "    categorical_columns = [col for col in df.columns if df[col].dtype == 'object']\n",
        "    df = pd.get_dummies(df, columns= categorical_columns, dummy_na= nan_as_category)\n",
        "    new_columns = [c for c in df.columns if c not in original_columns]\n",
        "    return df, new_columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMagoBp2tcWi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encode_label(app_train):\n",
        "  # Create a label encoder object\n",
        "  le = LabelEncoder()\n",
        "  le_count = 0\n",
        "\n",
        "  # Iterate through the columns\n",
        "  for col in app_train:\n",
        "      if app_train[col].dtype == 'object':\n",
        "          # If 2 or fewer unique categories\n",
        "          if len(list(app_train[col].unique())) <= 2:\n",
        "              # Train on the training data\n",
        "              le.fit(app_train[col])\n",
        "              # Transform both training and testing data\n",
        "              app_train[col] = le.transform(app_train[col])              \n",
        "              # Keep track of how many columns were label encoded\n",
        "              le_count += 1\n",
        "              \n",
        "  print('%d columns were label encoded.' % le_count)\n",
        "  return app_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBJDRqxLHV17",
        "colab_type": "text"
      },
      "source": [
        "# 2.Các hàm vẽ biểu đồ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glK6mdmNh5FZ",
        "colab_type": "text"
      },
      "source": [
        "## a. KDE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ID-Rb4OeHoKt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"FUNCTION: Kernel Density Estimation plot\n",
        "input: a dataframe --> output: a plot\n",
        "need: pandas, seaborn, matplotlib\n",
        "\"\"\"\n",
        "def create_plot_kdeplot(df, target_col_name, x_variable):\n",
        "\n",
        "    plt.figure(figsize = (10, 8))\n",
        "\n",
        "    # # KDE plot of loans that were repaid on time\n",
        "    # sns.kdeplot(\n",
        "    #     app_train.loc[app_train['TARGET'] == 0, 'DAYS_BIRTH'] / 365, \n",
        "    #     label = 'target == 0')\n",
        "\n",
        "    # # KDE plot of loans which were not repaid on time\n",
        "    # sns.kdeplot(\n",
        "    #     app_train.loc[app_train['TARGET'] == 1, 'DAYS_BIRTH'] / 365, \n",
        "    #     label = 'target == 1')\n",
        "\n",
        "    for i in target_values:\n",
        "        sns.kdeplot(\n",
        "            df.loc[df[target_col_name]== i, x_variable],\n",
        "            label = 'target == {}'.format(i)\n",
        "            )\n",
        "\n",
        "    # Labeling of plot\n",
        "    plt.xlabel('Age (years)'); \n",
        "    plt.ylabel('Density'); \n",
        "    plt.title('Distribution of Ages')\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wum8pBIjjvTD",
        "colab_type": "text"
      },
      "source": [
        "## b. Phân phối"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nLII3lDj0-o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"FUNCTION: plot stats https://www.kaggle.com/gpreda/home-credit-default-risk-extensive-eda\n",
        "input: dataframe --> output: a plot\n",
        "need pandas, matplotlib, seaborn.\n",
        "\"\"\"\n",
        "# def f_plot_stats(feature, label_rotation=False, horizontal_layout=True):\n",
        "\n",
        "\n",
        "\"\"\" FUNCTION: plot distribution \"\"\"\n",
        "def create_plot_one_distribution(feature, color):\n",
        "    plt.figure(figsize=(10,6)) #create a figure\n",
        "    plt.title(\"Distribution of %s\" % feature) #create a title for chart.\n",
        "    sns.distplot( #\n",
        "        application_train[feature].dropna(),\n",
        "        color=color, \n",
        "        kde=True,\n",
        "        bins=100)\n",
        "    plt.show()   \n",
        "\n",
        "\n",
        "\"\"\" FUNCTION: plot multiple features distribution\"\"\"\n",
        "def create_plot_multiple_distribution_comp(column_list,nrow=2):\n",
        "    \n",
        "    i = 0\n",
        "    t1 = application_train.loc[application_train['TARGET'] != 0]\n",
        "    t0 = application_train.loc[application_train['TARGET'] == 0]\n",
        "\n",
        "    sns.set_style('whitegrid')\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots(nrow,2,figsize=(12,6*nrow))\n",
        "\n",
        "    for feature in var:\n",
        "        i += 1\n",
        "        plt.subplot(nrow,2,i)\n",
        "        sns.kdeplot(t1[feature], bw=0.5,label=\"TARGET = 1\")\n",
        "        sns.kdeplot(t0[feature], bw=0.5,label=\"TARGET = 0\")\n",
        "        plt.ylabel('Density plot', fontsize=12)\n",
        "        plt.xlabel(feature, fontsize=12)\n",
        "        locs, labels = plt.xticks()\n",
        "        plt.tick_params(axis='both', which='major', labelsize=12)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIwQLvMckE9b",
        "colab_type": "text"
      },
      "source": [
        "## c. Histogram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_h81GElHNtZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"FUNCTION: plot histogram\"\"\"\n",
        "def create_plot_histogram(df,col_name,titleName,xlabelName):\n",
        "    df[col_name].plot.hist(title = titleName)\n",
        "    plt.xlabel(xlabelName)\n",
        "\"\"\"example\n",
        "plot_histogram(df = data,\n",
        "               col_name = 'DAYS_EMPLOYED',\n",
        "               titleName = 'Days Employment Histogram',\n",
        "               xlabelName = 'Days Employment')\n",
        "\"\"\"               "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBm2j9_yIJVm",
        "colab_type": "text"
      },
      "source": [
        "# 3.Các hàm về correlation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iezII2_yIM9Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"FUNTION: top 3 correlation with Target and bottom 3 correlation\n",
        "input: a dataframe MxN --> output: a dataframe Nx2\n",
        "need: pandas\n",
        "\"\"\"\n",
        "def create_table_top_corr(df, target_col_name):\n",
        "    correlations = df.corr()[target_col_name].sort_values()\n",
        "\n",
        "    print('Most Positive Correlations:\\n', correlations.tail(3))\n",
        "    print('\\nMost Negative Correlations:\\n', correlations.head(3))\n",
        "\n",
        "\n",
        "# Calculate all correlations in dataframe\n",
        "corrs = train.corr()\n",
        "\n",
        "corrs = corrs.sort_values('TARGET', ascending = False)\n",
        "\n",
        "# Ten most positive correlations\n",
        "pd.DataFrame(corrs['TARGET'].head(10))\n",
        "# Ten most negative correlations\n",
        "pd.DataFrame(corrs['TARGET'].dropna().tail(10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yszkTWixTh7r",
        "colab_type": "text"
      },
      "source": [
        "# 4.Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjpIAwz6qAa_",
        "colab_type": "text"
      },
      "source": [
        "## with Sklearn Library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTzTuXwnTpOU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from sklearn.linear_model import LogisticRegression\n",
        "# log_reg = LogisticRegression() \n",
        "# \"\"\"\n",
        "# create a model.\n",
        "# type(log_reg)\n",
        "# <class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
        "# \"\"\"\n",
        "\n",
        "# # Load data\n",
        "# y = app_train['TARGET']\n",
        "# X = app_train.drop(columns = ['TARGET'])\n",
        "# # Cleansing & Transformation pipeline\n",
        "\n",
        "# # Split X and y into training and testing sets\n",
        "# from sklearn.cross_validation import train_test_split\n",
        "# X_train,X_test,y_train,y_test=train_test_split(\n",
        "#                                           X,\n",
        "#                                           y,\n",
        "#                                           test_size=0.25,\n",
        "#                                           random_state=0)\n",
        "\n",
        "\n",
        "# # Fit\n",
        "# log_reg.fit(X, y)\n",
        "# \"\"\"\n",
        "# 'fit' is a method of class 'linear_model'. it receives \n",
        "# dataframe X and vector y, as input, \n",
        "# and return self. \n",
        "# after we run .fit, we can run .predict\n",
        "# \"\"\"\n",
        "\n",
        "# # Predict\n",
        "# y_pred = log_reg.predict(X_test) #log_reg.predict([[1.7], [1.5]])\n",
        "# \"\"\"\n",
        "# 'predict' is a method.\n",
        "# it receive dataframe X as input, \n",
        "# and return 'Predicted class label per sample'.\n",
        "# \"\"\"\n",
        "\n",
        "# # Evaluation\n",
        "# # 1.Confustion Matrix\n",
        "# from sklearn import metrics\n",
        "# df_confusion_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
        "# df_confusion_matrix\n",
        "\n",
        "# # 2.Accuracy-Precision-Recall, on test set\n",
        "# print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
        "# print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
        "# print(\"Recall:\",metrics.recall_score(y_test, y_pred))\n",
        "\n",
        "# # 3.F1-score\n",
        "# from sklearn.metrics import f1_score\n",
        "# f1_score(\n",
        "#       y_test, \n",
        "#       y_pred, \n",
        "#       average='weighted')\n",
        "# --0.9731332318832974\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abghRpv-KL-r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Example\n",
        ">>> from sklearn import datasets\n",
        ">>> iris = datasets.load_iris()\n",
        ">>> type(iris)\n",
        "# <class 'sklearn.utils.Bunch'>\n",
        ">>> X = iris[\"data\"][:,3:]\n",
        ">>> type(X)\n",
        "# <class 'numpy.ndarray'>\n",
        ">>> y = (iris[\"target\"]==2).astype(np.int)\n",
        ">>> type(y)\n",
        "# <class 'numpy.ndarray'>\n",
        ">>> from sklearn.linear_model import LogisticRegression\n",
        ">>> LogisticRegression().fit(X,y)\n",
        "# LogisticRegression()\n",
        "\n",
        ">>> X.shape\n",
        "(150, 1)\n",
        ">>> y.shape\n",
        "(150,)\n",
        ">>> X_train,X_test,y_train,y_test=train_test_split(\n",
        "...                                           X,\n",
        "...                                           y,\n",
        "...                                           test_size=0.25,\n",
        "...                                           random_state=0)\n",
        ">>> LogisticRegression().fit(X_train,y_train)\n",
        "# LogisticRegression()\n",
        ">>> y_pred = log_reg.predict(X_test)\n",
        ">>> from sklearn import metrics\n",
        ">>> df_confusion_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
        ">>> df_confusion_matrix\n",
        "# array([[29,  0],\n",
        "#        [ 1,  8]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amWcXsDow_cs",
        "colab_type": "text"
      },
      "source": [
        "### why need .predict_proba() ???"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0zWTtyxw4JZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://stats.stackexchange.com/questions/391681/logisticregression-sklearn-why-does-predict-proba-yield-better-results/391757\n",
        "\n",
        "# check classification scores of logistic regression\n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(X_train, y_train)\n",
        "# y_pred = logreg.predict(X_test)\n",
        "y_pred_proba = logreg.predict_proba(X_test)[:, 1]\n",
        "[fpr, tpr, thr] = roc_curve(y_test, y_pred_proba)\n",
        "# print('Train/Test split results:')\n",
        "# print(logreg.__class__.__name__+\" accuracy is %2.3f\" % accuracy_score(y_test, y_pred))\n",
        "print(logreg.__class__.__name__+\" log_loss is %2.3f\" % log_loss(y_test, y_pred_proba))\n",
        "# print(logreg.__class__.__name__+\" auc is %2.3f\" % auc(fpr, tpr))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ty_N2pSxJAu",
        "colab_type": "text"
      },
      "source": [
        "### cross validation with Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yxfLQ_0xNvM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 10-fold cross-validation logistic regression\n",
        "logreg = LogisticRegression()\n",
        "# Use cross_val_score function\n",
        "# We are passing the entirety of X and y, not X_train or y_train, it takes care of splitting the data\n",
        "# cv=10 for 10 folds\n",
        "# scoring = {'accuracy', 'neg_log_loss', 'roc_auc'} for evaluation metric - althought they are many\n",
        "scores_accuracy = cross_val_score(logreg, X, y, cv=10, scoring='accuracy')\n",
        "# scores_log_loss = cross_val_score(logreg, X, y, cv=10, scoring='neg_log_loss')\n",
        "# scores_auc = cross_val_score(logreg, X, y, cv=10, scoring='roc_auc')\n",
        "print('K-fold cross-validation results:')\n",
        "print(logreg.__class__.__name__+\" average accuracy is %2.3f\" % scores_accuracy.mean())\n",
        "# print(logreg.__class__.__name__+\" average log_loss is %2.3f\" % -scores_log_loss.mean())\n",
        "# print(logreg.__class__.__name__+\" average auc is %2.3f\" % scores_auc.mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRQBlOGlqKjv",
        "colab_type": "text"
      },
      "source": [
        "## logistic regression, with Statsmodel library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsOm4qn_qObF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import statsmodels.api as sm\n",
        "# excl = ['mean radius','mean perimeter','mean area',\n",
        "#         'worst area','worst perimeter','worst radius',\n",
        "#         'radius error','perimeter error','area error']\n",
        "# X_train = scaler.fit_transform(X_train.drop(excl,axis=1))\n",
        "\n",
        "\n",
        "model = sm.Logit(y_train, X_train).fit()\n",
        "print(model.summary())\n",
        "\n",
        "y_scores = model.predict(scaler.fit_transform(X_test.drop(excl,axis=1)))\n",
        "\n",
        "y_pred = (y_scores >0.5).astype(int)\n",
        "\n",
        "accuracy_score(y_test.values.ravel(), y_pred)\n",
        "# 0.9210526315789473"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIak9AuoE4MN",
        "colab_type": "text"
      },
      "source": [
        "# 5.Evaluation\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWkQ5n3mrEH0",
        "colab_type": "text"
      },
      "source": [
        "## cross validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eur5Idf8E-MH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Example: with a classifier call SGDClassifier, from \"Hands on ML/Chapter3\"\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "sgd_clf = SGDClassifier(random_state=42) sgd_clf.fit(X_train, y_train_5)\n",
        "\n",
        "#Cross Validation\n",
        "from sklearn.model_selection import cross_val_score\n",
        "#Cross Validation with \"Accuracy\"\n",
        "cross_val_score(sgd_clf, X_train, y_train_5, cv=3, scoring=\"accuracy\") \n",
        "# array([0.96355, 0.93795, 0.95615])\n",
        "\n",
        "\n",
        "from sklearn.model_selection import cross_val_predict \n",
        "y_train_pred = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(y_train_5, y_train_pred) \n",
        "#array([[53057, 1522], [ 1325, 4096]])\n",
        "\n",
        "\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "precision_score(y_train_5, y_train_pred) # == 4096 / (4096 + 1522)\n",
        "#0.7290850836596654\n",
        "recall_score(y_train_5, y_train_pred) # == 4096 / (4096 + 1325)\n",
        "#0.7555801512636044\n",
        "from sklearn.metrics import f1_score\n",
        "f1_score(y_train_5, y_train_pred)\n",
        "#0.7420962043663375"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLRhiOSyICHG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Another example with a classifier call RandomForestClassifier \n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "forest_clf = RandomForestClassifier(random_state=42) \n",
        "y_probas_forest = cross_val_predict(\n",
        "                            forest_clf, \n",
        "                            X_train, \n",
        "                            y_train_5, \n",
        "                            cv=3, \n",
        "                            method=\"predict_proba\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzlsmBvuIbww",
        "colab_type": "text"
      },
      "source": [
        "Some algorithms (such as SGD classifiers, Random Forest classifiers, and naive Bayes classifiers) are capable of handling multiple classes natively. Others (such as Logistic Regression or Support Vector Machine classifiers) are strictly binary classifiers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_L0PB-aIrQG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# #multiclass classifier Confusion Matrix looks like this\n",
        "# >>> y_train_pred = cross_val_predict(sgd_clf, X_train_scaled, y_train, cv=3)\n",
        "\n",
        "# >>> conf_mx = confusion_matrix(y_train, y_train_pred)\n",
        "\n",
        "# >>> conf_mx \n",
        "# array([[5578, 0, 22, 7, 8, 45, 35, 5, 222, 1], \n",
        "#        [ 0, 6410, 35, 26, 4, 44, 4, 8, 198, 13], \n",
        "#        [ 28, 27, 5232, 100, 74, 27, 68, 37, 354, 11], \n",
        "#        [ 23, 18, 115, 5254, 2, 209, 26, 38, 373, 73], \n",
        "#        [ 11, 14, 45, 12, 5219, 11, 33, 26, 299, 172], \n",
        "#        [ 26, 16, 31, 173, 54, 4484, 76, 14, 482, 65], \n",
        "#        [ 31, 17, 45, 2, 42, 98, 5556, 3, 123, 1], \n",
        "#        [ 20, 10, 53, 27, 50, 13, 3, 5696, 173, 220], \n",
        "#        [ 17, 64, 47, 91, 3, 125, 24, 11, 5421, 48], \n",
        "#        [ 24, 18, 29, 67, 116, 39, 1, 174, 329, 5152]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKgdM2nxLdHl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#An example of SVM Classifier \n",
        "from sklearn.preprocessing import StandardScaler \n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "iris = datasets.load_iris() \n",
        "X = iris[\"data\"][:, (2, 3)] # petal length, petal width \n",
        "y = (iris[\"target\"] == 2).astype(np.float64) # Iris virginica\n",
        "\n",
        "svm_clf = Pipeline([ \n",
        "                    (\"scaler\", StandardScaler()),\n",
        "                    (\"linear_svc\", LinearSVC(C=1, loss=\"hinge\")),\n",
        "                    ])\n",
        "\n",
        "svm_clf.fit(X, y)\n",
        "\n",
        ">>> svm_clf.predict([[5.5, 1.7]])\n",
        "# array([1.])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_V2GhuDX1c3V",
        "colab_type": "text"
      },
      "source": [
        "## confusion matrix "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJYEguPK1kAt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xSyg20Z1klk",
        "colab_type": "text"
      },
      "source": [
        "## F1-score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdjOlYk1hXm9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import \n",
        "score = sklearn.metrics.f1_score(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSRhSbct1nX6",
        "colab_type": "text"
      },
      "source": [
        "## ROC AUC score\n",
        "\n",
        "An AUC score of 0.5 is effectively as good as the flip of a coin, and means that the model really has no classification power at all between the positive and negative occurences. \n",
        "\n",
        "\"AUC of a classifier is equivalent to the probability that the classifier will rank a randomly chosen positive instance higher than a randomly chosen negative instance.\" -Majnik, Bosnic, 2011\n",
        "\n",
        "https://www.kaggle.com/sgus1318/titanic-analysis-learning-to-swim-with-python"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpQOmwU27n8s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# (Nam điền code ROC AUC vào đây)\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "score = roc_auc_score(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkW8qHfV0gww",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# 6.Các hàm chưa phân loại"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSd5kebZ3Rzh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Chọn, select data từ một dataframe\n",
        "\"\"\" select from where [condition] \"\"\"\n",
        "\n",
        "# Thay vì viết\n",
        "df_abc = application_train[application_train.TARGET==1]\n",
        "# Nên viết\n",
        "df_abc = application_train.loc[application_train.TARGET==1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-lpfCPqaujP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model(train_features, test_features, encoding = 'ohe', n_folds = 5):\n",
        "    \n",
        "    \"\"\"Train and test a light gradient boosting model using\n",
        "    cross validation. \n",
        "    \n",
        "    Parameters\n",
        "    --------\n",
        "        features (pd.DataFrame): \n",
        "            dataframe of training features to use \n",
        "            for training a model. Must include the TARGET column.\n",
        "        test_features (pd.DataFrame): \n",
        "            dataframe of testing features to use\n",
        "            for making predictions with the model. \n",
        "        encoding (str, default = 'ohe'): \n",
        "            method for encoding categorical variables. Either 'ohe' for one-hot encoding or 'le' for integer label encoding\n",
        "            n_folds (int, default = 5): number of folds to use for cross validation\n",
        "        \n",
        "    Return\n",
        "    --------\n",
        "        submission (pd.DataFrame): \n",
        "            dataframe with `SK_ID_CURR` and `TARGET` probabilities\n",
        "            predicted by the model.\n",
        "        feature_importances (pd.DataFrame): \n",
        "            dataframe with the feature importances from the model.\n",
        "        valid_metrics (pd.DataFrame): \n",
        "            dataframe with training and validation metrics (ROC AUC) for each fold and overall.\n",
        "        \n",
        "    \"\"\"\n",
        "    \n",
        "    # Extract the ids\n",
        "    train_ids = train_features['SK_ID_CURR']\n",
        "    test_ids = test_features['SK_ID_CURR']\n",
        "    \n",
        "    # Extract the labels for training\n",
        "    labels = train_features['TARGET']\n",
        "    \n",
        "    # Remove the ids and target\n",
        "    train_features = train_features.drop(columns = ['SK_ID_CURR', 'TARGET'])\n",
        "    test_features = test_features.drop(columns = ['SK_ID_CURR'])\n",
        "    \n",
        "    \n",
        "    # One Hot Encoding\n",
        "    if encoding == 'ohe':\n",
        "        train_features = pd.get_dummies(train_features)\n",
        "        test_features = pd.get_dummies(test_features)\n",
        "        \n",
        "        # Align the dataframes by the columns\n",
        "        train_features, test_features = train_features.align(test_features, join = 'inner', axis = 1)\n",
        "        \n",
        "        # No categorical indices to record\n",
        "        cat_indices = 'auto'\n",
        "    \n",
        "    # Integer label encoding\n",
        "    elif encoding == 'le':\n",
        "        \n",
        "        # Create a label encoder\n",
        "        label_encoder = LabelEncoder()\n",
        "        \n",
        "        # List for storing categorical indices\n",
        "        cat_indices = []\n",
        "        \n",
        "        # Iterate through each column\n",
        "        for i, col in enumerate(train_features):\n",
        "            if train_features[col].dtype == 'object':\n",
        "                # Map the categorical features to integers\n",
        "                train_features[col] = label_encoder.fit_transform(np.array(train_features[col].astype(str)).reshape((-1,)))\n",
        "                test_features[col] = label_encoder.transform(np.array(test_features[col].astype(str)).reshape((-1,)))\n",
        "\n",
        "                # Record the categorical indices\n",
        "                cat_indices.append(i)\n",
        "    \n",
        "    # Catch error if label encoding scheme is not valid\n",
        "    else:\n",
        "        raise ValueError(\"Encoding must be either 'ohe' or 'le'\")\n",
        "        \n",
        "    print('Training Data Shape: ', train_features.shape)\n",
        "    print('Testing Data Shape: ', test_features.shape)\n",
        "    \n",
        "    # Extract feature names\n",
        "    feature_names = list(train_features.columns)\n",
        "    \n",
        "    # Convert to np arrays\n",
        "    train_features = np.array(train_features)\n",
        "    test_features = np.array(test_features)\n",
        "    \n",
        "    # Create the kfold object\n",
        "    k_fold = KFold(n_splits = n_folds, shuffle = False, random_state = 50)\n",
        "    \n",
        "    # Empty array for feature importances\n",
        "    feature_importance_values = np.zeros(len(feature_names))\n",
        "    \n",
        "    # Empty array for test predictions\n",
        "    test_predictions = np.zeros(test_features.shape[0])\n",
        "    \n",
        "    # Empty array for out of fold validation predictions\n",
        "    out_of_fold = np.zeros(train_features.shape[0])\n",
        "    \n",
        "    # Lists for recording validation and training scores\n",
        "    valid_scores = []\n",
        "    train_scores = []\n",
        "    \n",
        "    # Iterate through each fold\n",
        "    for train_indices, valid_indices in k_fold.split(train_features):\n",
        "        \n",
        "        # Training data for the fold\n",
        "        train_features, train_labels = train_features[train_indices], labels[train_indices]\n",
        "        # Validation data for the fold\n",
        "        valid_features, valid_labels = train_features[valid_indices], labels[valid_indices]\n",
        "        \n",
        "        # Create the model\n",
        "        model = lgb.LGBMClassifier(n_estimators=10000, objective = 'binary', \n",
        "                                   class_weight = 'balanced', learning_rate = 0.05, \n",
        "                                   reg_alpha = 0.1, reg_lambda = 0.1, \n",
        "                                   subsample = 0.8, n_jobs = -1, random_state = 50)\n",
        "        \n",
        "        # Train the model\n",
        "        model.fit(train_features, train_labels, eval_metric = 'auc',\n",
        "                  eval_set = [(valid_features, valid_labels), (train_features, train_labels)],\n",
        "                  eval_names = ['valid', 'train'], categorical_feature = cat_indices,\n",
        "                  early_stopping_rounds = 100, verbose = 200)\n",
        "        \n",
        "        # Record the best iteration\n",
        "        best_iteration = model.best_iteration_\n",
        "        \n",
        "        # Record the feature importances\n",
        "        feature_importance_values += model.feature_importances_ / k_fold.n_splits\n",
        "        \n",
        "        # Make predictions\n",
        "        test_predictions += model.predict_proba(test_features, num_iteration = best_iteration)[:, 1] / k_fold.n_splits\n",
        "        \n",
        "        # Record the out of fold predictions\n",
        "        out_of_fold[valid_indices] = model.predict_proba(valid_features, num_iteration = best_iteration)[:, 1]\n",
        "        \n",
        "        # Record the best score\n",
        "        valid_score = model.best_score_['valid']['auc']\n",
        "        train_score = model.best_score_['train']['auc']\n",
        "        \n",
        "        valid_scores.append(valid_score)\n",
        "        train_scores.append(train_score)\n",
        "        \n",
        "        # Clean up memory\n",
        "        gc.enable()\n",
        "        del model, train_features, valid_features\n",
        "        gc.collect()\n",
        "        \n",
        "    # Make the submission dataframe\n",
        "    submission = pd.DataFrame({'SK_ID_CURR': test_ids, 'TARGET': test_predictions})\n",
        "    \n",
        "    # Make the feature importance dataframe\n",
        "    feature_importances = pd.DataFrame({'feature': feature_names, 'importance': feature_importance_values})\n",
        "    \n",
        "    # Overall validation score\n",
        "    valid_auc = roc_auc_score(labels, out_of_fold)\n",
        "    \n",
        "    # Add the overall scores to the metrics\n",
        "    valid_scores.append(valid_auc)\n",
        "    train_scores.append(np.mean(train_scores))\n",
        "    \n",
        "    # Needed for creating dataframe of validation scores\n",
        "    fold_names = list(range(n_folds))\n",
        "    fold_names.append('overall')\n",
        "    \n",
        "    # Dataframe of validation scores\n",
        "    metrics = pd.DataFrame({'fold': fold_names,\n",
        "                            'train': train_scores,\n",
        "                            'valid': valid_scores}) \n",
        "    \n",
        "    return submission, feature_importances, metrics\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5kNH4aJIH8t",
        "colab_type": "text"
      },
      "source": [
        "## Join data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJELsqPg9s1-",
        "colab_type": "text"
      },
      "source": [
        "### Aggregate variables from 6 other tables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efmD0woY94ot",
        "colab_type": "text"
      },
      "source": [
        "### pandas MERGE & pandas JOIN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOJWrTkqIMEL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" \n",
        "pd.merge https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.merge.html\n",
        "\n",
        "-left vs inner join: df1.join(df2) does a left join by default (keeps all rows of df1), \n",
        "but df.merge does an inner join by default (returns only matching rows of df1 and df2).\n",
        "-So, the generic approach is to use pandas.merge(df1, df2) or df1.merge(df2). \n",
        "But for a number of common situations (keeping all rows of df1 and joining \n",
        "to an index in df2), you can save some typing by using df1.join(df2) instead.\n",
        "https://stackoverflow.com/questions/22676081/what-is-the-difference-between-join-and-merge-in-pandas\n",
        "\n",
        "https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "train_labels = train_bureau['TARGET']\n",
        "previous_features.append('SK_ID_CURR')\n",
        "\n",
        "train_ids = train_bureau['SK_ID_CURR']\n",
        "test_ids = test_bureau['SK_ID_CURR']\n",
        "\n",
        "# Merge the dataframes avoiding duplicating columns by subsetting train_previous\n",
        "train = train_bureau.merge(train_previous[previous_features], on = 'SK_ID_CURR') #pd.dataframe.merge()\n",
        "test = test_bureau.merge(test_previous[previous_features], on = 'SK_ID_CURR')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HoCD1_c9IaEj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#align \n",
        "# Match the columns in the dataframes\n",
        "train, test = train.align(test, join = 'inner', axis = 1)\n",
        "print('Training shape: ', train.shape)\n",
        "print('Testing shape: ', test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCDsjkObVRIi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def merge(df):\n",
        "    df = df.join(data_bureau_agg, how='left', on='SK_ID_CURR', lsuffix='1', rsuffix='2') \n",
        "    df = df.join(bureau_counts, on = 'SK_ID_CURR', how = 'left')\n",
        "    df = df.merge(previous_loan_counts, on = 'SK_ID_CURR', how = 'left')\n",
        "    df = df.join(data_credit_card_balance_agg, how='left', on='SK_ID_CURR', lsuffix='1', rsuffix='2')    \n",
        "    df = df.join(data_previous_application_agg, how='left', on='SK_ID_CURR', lsuffix='1', rsuffix='2')   \n",
        "    df = df.join(data_installments_payments_agg, how='left', on='SK_ID_CURR', lsuffix='1', rsuffix='2') \n",
        "    \n",
        "    return df\n",
        "\n",
        "train = merge(app_train)\n",
        "test = merge(app_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zK718lrKNPLr",
        "colab_type": "text"
      },
      "source": [
        "# Feature Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFcwMxeaNV3D",
        "colab_type": "text"
      },
      "source": [
        "## remove Collinear variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJstGyr0NdE7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Threshold for removing correlated variables\n",
        "threshold = 0.9\n",
        "\n",
        "# Absolute value correlation matrix\n",
        "corr_matrix = train.corr().abs()\n",
        "corr_matrix.head()\n",
        "\n",
        "# Upper triangle of correlations\n",
        "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
        "upper.head()\n",
        "\n",
        "to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
        "print('There are %d columns to remove.' % (len(to_drop)))\n",
        "\n",
        "train = train.drop(columns = to_drop)\n",
        "test = test.drop(columns = to_drop)\n",
        "\n",
        "print('Training shape: ', train.shape)\n",
        "print('Testing shape: ', test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahCSLiVIXzHE",
        "colab_type": "text"
      },
      "source": [
        "## select top 15 features to keep"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyJjcSieX3P2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Threshold for cumulative importance\n",
        "# threshold = 0.95\n",
        "\n",
        "# # Extract the features to keep\n",
        "# features_to_keep = list(norm_feature_importances[norm_feature_importances['cumulative_importance'] < threshold]['feature'])\n",
        "\n",
        "# # Create new datasets with smaller features\n",
        "# train_small = train[features_to_keep]\n",
        "# test_small = test[features_to_keep]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XK4VimwmiCk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cach 1\n",
        "list_column = []\n",
        "selected_X_train = X_train[list_column]\n",
        "\n",
        "# Cach 2\n",
        "features = list(train_gr.columns)\n",
        "selected_X_train = X_train[features]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFZnT_HlsQss",
        "colab_type": "text"
      },
      "source": [
        "## Dimensionality Reduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ve9dcdTrsWiO",
        "colab_type": "text"
      },
      "source": [
        "### PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQy0BEnIsYBr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components = 154) \n",
        "X_reduced = pca.fit_transform(X_train) \n",
        "X_recovered = pca.inverse_transform(X_reduced)\n",
        "\n",
        "# HOAC \n",
        "from sklearn.decomposition import PCA\n",
        "pca = PCA()\n",
        "X_train = pca.fit_transform(X_train)\n",
        "pca.explained_variance_ratio_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEgGQYprzm1L",
        "colab_type": "text"
      },
      "source": [
        "# Submit to Kaggle competition (cant do it now)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoaaIXGhzqka",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_test['Survived'] = log_clf.predict(final_test[Selected_features])\n",
        "final_test['PassengerId'] = test_df['PassengerId']\n",
        "\n",
        "submission = final_test[['PassengerId','Survived']]\n",
        "\n",
        "submission.to_csv(\"submission.csv\", index=False)\n",
        "\n",
        "submission.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xx4_50HxAOCb",
        "colab_type": "text"
      },
      "source": [
        "# Explanable ML"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RrNUt_eAARdn",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}