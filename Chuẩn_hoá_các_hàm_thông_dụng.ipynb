{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chuẩn hoá các hàm thông dụng.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ngonam2403/VEF-Final-Project_202007/blob/master/Chu%E1%BA%A9n_ho%C3%A1_c%C3%A1c_h%C3%A0m_th%C3%B4ng_d%E1%BB%A5ng.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmrClbBifz9l",
        "colab_type": "text"
      },
      "source": [
        "# 0.Mục đích"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9_g8VWyaptW",
        "colab_type": "text"
      },
      "source": [
        "Format chung: \n",
        "1. mục đích hàm\n",
        "2. input (dataframe, list) --> output (number, dataframe, chart)\n",
        "3. cần library nào để chạy? pandas, numpy, scikitlearn, seaborn\n",
        "\n",
        "---\n",
        "Mục đích: để tra cứu & tái sử dụng\n",
        "\n",
        "---\n",
        "Cách đặt tên phần tử (Naming Convention): mục đích của việc này là để người khác dễ đọc và mường tượng được code của mình.\n",
        "thứ tự ưu tiên: mục đích -> loại -> tên riêng để định danh.\n",
        "- hàm: động từ, ví dụ def create_table() hoặc def plot_chart().\n",
        "- biến: danh từ\n",
        "  - dataframe: df_, ví dụ: thay vì viết data = pd.read_csv() thì viết df_abc = pd.read_csv(). nếu dataframe là một param trong hàm thì nên viết def create_table(param_df_xyz).\n",
        "  - một con số: num_\n",
        "  - text: str_\n",
        "    \n",
        "- lúc dùng thì ghi rõ param1 = , param2 =, param3 = \n",
        "- khi hàm có quá nhiều param thì chuyển sang dùng class,\n",
        "- class: CamelCase\n",
        "\n",
        "- tham khảo: https://www.analyticsvidhya.com/blog/2020/07/python-style-guide/; https://towardsdatascience.com/data-scientists-your-variable-names-are-awful-heres-how-to-fix-them-89053d2855be\n",
        "---\n",
        "flow chạy, pipeline.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_248h71Tfw1x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Don't do this\n",
        "temp = get_house_price_in_usd(house_sqft, house_room_count)\n",
        "final_value = temp * usd_to_aud_conversion_rate\n",
        "# Do this instead\n",
        "house_price_in_usd = get_house_price_in_usd(house_sqft, \n",
        "                                            house_room_count)\n",
        "house_price_in_aud = house_price_in_usd * usd_to_aud_conversion_rate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9nXaaW2g3dX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for row_index in range(row_count):\n",
        "    for column_index in range(column_count):\n",
        "        ...."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TPuhfdohFN5",
        "colab_type": "text"
      },
      "source": [
        "The benefits of adopting standards are that they let you make a single global decision instead of many local ones."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7otUwK3khF9u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVkFWK4g0b2s",
        "colab_type": "text"
      },
      "source": [
        "# 1.Các hàm xử lý missing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLxReWS7VWe5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "FUNCTION: CHECK MISSING DATA\n",
        "input: a dataframe MxN --> output: a dataframe Nx2\n",
        "need: pandas\n",
        "\"\"\"\n",
        "def create_table_missing_values(df):\n",
        "    mis_val = df.isnull().sum() #total missing values #input: df MxN -> output: df Nx2\n",
        "    mis_val_percent = 100 * df.isnull().sum() / len(df) #percentage of missing values #input: df MxN -> output: df Nx2\n",
        "    mis_val_table = pd.concat( #join df mis_val and df mis_val_percent\n",
        "        [mis_val, mis_val_percent], \n",
        "        axis=1\n",
        "        ) \n",
        "    mis_val_table_ren_columns = mis_val_table.rename( #rename the columns\n",
        "        columns = {\n",
        "            0 : 'Missing values', \n",
        "            1 : '% of Total Values'\n",
        "            }\n",
        "        )\n",
        "    mis_val_table_ren_columns = mis_val_table_ren_columns[ #sort the table by percentage of missing descending\n",
        "        mis_val_table_ren_columns.iloc[:,1] != 0].sort_values('% of Total Values', ascending=False).round(1) #exclude those has 0% missing.\n",
        "    \n",
        "    print(\"Your selected dataframe has \")    \n",
        "    return mis_val_table_ren_columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBJDRqxLHV17",
        "colab_type": "text"
      },
      "source": [
        "# 2.Các hàm vẽ biểu đồ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glK6mdmNh5FZ",
        "colab_type": "text"
      },
      "source": [
        "## a. KDE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ID-Rb4OeHoKt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"FUNCTION: Kernel Density Estimation plot\n",
        "input: a dataframe --> output: a plot\n",
        "need: pandas, seaborn, matplotlib\n",
        "\"\"\"\n",
        "def create_plot_kdeplot(df, target_col_name, x_variable):\n",
        "\n",
        "    plt.figure(figsize = (10, 8))\n",
        "\n",
        "    # # KDE plot of loans that were repaid on time\n",
        "    # sns.kdeplot(\n",
        "    #     app_train.loc[app_train['TARGET'] == 0, 'DAYS_BIRTH'] / 365, \n",
        "    #     label = 'target == 0')\n",
        "\n",
        "    # # KDE plot of loans which were not repaid on time\n",
        "    # sns.kdeplot(\n",
        "    #     app_train.loc[app_train['TARGET'] == 1, 'DAYS_BIRTH'] / 365, \n",
        "    #     label = 'target == 1')\n",
        "\n",
        "    for i in target_values:\n",
        "        sns.kdeplot(\n",
        "            df.loc[df[target_col_name]== i, x_variable],\n",
        "            label = 'target == {}'.format(i)\n",
        "            )\n",
        "\n",
        "    # Labeling of plot\n",
        "    plt.xlabel('Age (years)'); \n",
        "    plt.ylabel('Density'); \n",
        "    plt.title('Distribution of Ages')\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wum8pBIjjvTD",
        "colab_type": "text"
      },
      "source": [
        "## b. Phân phối"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nLII3lDj0-o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "1674277f-2c07-4c07-ae5f-ceb948b23c22"
      },
      "source": [
        "\"\"\"FUNCTION: plot stats https://www.kaggle.com/gpreda/home-credit-default-risk-extensive-eda\n",
        "input: dataframe --> output: a plot\n",
        "need pandas, matplotlib, seaborn.\n",
        "\"\"\"\n",
        "# def f_plot_stats(feature, label_rotation=False, horizontal_layout=True):\n",
        "\n",
        "\n",
        "\"\"\" FUNCTION: plot distribution \"\"\"\n",
        "def create_plot_one_distribution(feature, color):\n",
        "    plt.figure(figsize=(10,6)) #create a figure\n",
        "    plt.title(\"Distribution of %s\" % feature) #create a title for chart.\n",
        "    sns.distplot( #\n",
        "        application_train[feature].dropna(),\n",
        "        color=color, \n",
        "        kde=True,\n",
        "        bins=100)\n",
        "    plt.show()   \n",
        "\n",
        "\n",
        "\"\"\" FUNCTION: plot multiple features distribution\"\"\"\n",
        "def create_plot_multiple_distribution_comp(column_list,nrow=2):\n",
        "    \n",
        "    i = 0\n",
        "    t1 = application_train.loc[application_train['TARGET'] != 0]\n",
        "    t0 = application_train.loc[application_train['TARGET'] == 0]\n",
        "\n",
        "    sns.set_style('whitegrid')\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots(nrow,2,figsize=(12,6*nrow))\n",
        "\n",
        "    for feature in var:\n",
        "        i += 1\n",
        "        plt.subplot(nrow,2,i)\n",
        "        sns.kdeplot(t1[feature], bw=0.5,label=\"TARGET = 1\")\n",
        "        sns.kdeplot(t0[feature], bw=0.5,label=\"TARGET = 0\")\n",
        "        plt.ylabel('Density plot', fontsize=12)\n",
        "        plt.xlabel(feature, fontsize=12)\n",
        "        locs, labels = plt.xticks()\n",
        "        plt.tick_params(axis='both', which='major', labelsize=12)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-b059c9ec2854>\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    \"\"\" FUNCTION: plot distribution \"\"\"\u001b[0m\n\u001b[0m                                      ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIwQLvMckE9b",
        "colab_type": "text"
      },
      "source": [
        "## c. Histogram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_h81GElHNtZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"FUNCTION: plot histogram\"\"\"\n",
        "def create_plot_histogram(df,col_name,titleName,xlabelName):\n",
        "    df[col_name].plot.hist(title = titleName)\n",
        "    plt.xlabel(xlabelName)\n",
        "\"\"\"example\n",
        "plot_histogram(df = data,\n",
        "               col_name = 'DAYS_EMPLOYED',\n",
        "               titleName = 'Days Employment Histogram',\n",
        "               xlabelName = 'Days Employment')\n",
        "\"\"\"               "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBm2j9_yIJVm",
        "colab_type": "text"
      },
      "source": [
        "# 3.Các hàm về correlation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iezII2_yIM9Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"FUNTION: top 3 correlation with Target and bottom 3 correlation\n",
        "input: a dataframe MxN --> output: a dataframe Nx2\n",
        "need: pandas\n",
        "\"\"\"\n",
        "def create_table_top_corr(df, target_col_name):\n",
        "    correlations = df.corr()[target_col_name].sort_values()\n",
        "\n",
        "    print('Most Positive Correlations:\\n', correlations.tail(3))\n",
        "    print('\\nMost Negative Correlations:\\n', correlations.head(3))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yszkTWixTh7r",
        "colab_type": "text"
      },
      "source": [
        "# 4.Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTzTuXwnTpOU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "log_reg = LogisticRegression() \n",
        "\"\"\"\n",
        "create a model.\n",
        "type(log_reg)\n",
        "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
        "\"\"\"\n",
        "\n",
        "# Load data\n",
        "# Cleansing & Transformation pipeline\n",
        "\n",
        "# Split X and y into training and testing sets\n",
        "from sklearn.cross_validation import train_test_split\n",
        "X_train,X_test,y_train,y_test=train_test_split(\n",
        "                                          X,\n",
        "                                          y,\n",
        "                                          test_size=0.25,\n",
        "                                          random_state=0)\n",
        "\n",
        "\n",
        "# Fit\n",
        "log_reg.fit(X, y)\n",
        "\"\"\"\n",
        "'fit' is a method of class 'linear_model'. it receives \n",
        "dataframe X and vector y, as input, \n",
        "and return self. \n",
        "after we run .fit, we can run .predict\n",
        "\"\"\"\n",
        "\n",
        "# Predict\n",
        "log_reg.predict(X_test) #log_reg.predict([[1.7], [1.5]])\n",
        "\"\"\"\n",
        "'predict' is a method.\n",
        "it receive dataframe X as input, \n",
        "and return 'Predicted class label per sample'.\n",
        "\"\"\"\n",
        "\n",
        "# Evaluation\n",
        "# 1.Confustion Matrix\n",
        "from sklearn import metrics\n",
        "df_confusion_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
        "df_confusion_matrix\n",
        "\n",
        "# 2.Accuracy-Precision-Recall, on test set\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
        "print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
        "print(\"Recall:\",metrics.recall_score(y_test, y_pred))\n",
        "\n",
        "# 3.F1-score\n",
        "from sklearn.metrics import f1_score\n",
        "f1_score(\n",
        "      y_test, \n",
        "      y_pred, \n",
        "      average='weighted')\n",
        "--0.9731332318832974\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkW8qHfV0gww",
        "colab_type": "text"
      },
      "source": [
        "# 6.Các hàm chưa phân loại"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0gFn8J03Buc",
        "colab_type": "text"
      },
      "source": [
        "## Chọn, select data từ một dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSd5kebZ3Rzh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" select from where [condition] \"\"\"\n",
        "\n",
        "# Thay vì viết\n",
        "df_abc = application_train[application_train.TARGET==1]\n",
        "# Nên viết\n",
        "df_abc = application_train.loc[application_train.TARGET==1]"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}